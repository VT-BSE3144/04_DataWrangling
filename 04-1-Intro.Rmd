---
title: "Data Transformation - Out of Class with reading"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Connection to previous work on Data Organization

We will finally see why organized data is worth the effort. We'll follow an exercise using a data source with over 300,000 rows! The work this week will show us (1) why R is awesome and fast for analysis, (2) reinforce the purpose of organized data (following the 12 best practices we learned in Week 1).

## Source

This exercise follows along with the reading for this week R for Data Science Chapter 5 <https://r4ds.had.co.nz/transform.html>. The template below is for you to be able to follow along in the reading and complete the exercises.

## 5.1.1

I've gone ahead and loaded the 2 packages, but you need to turn them "on". Below, follow the instructions using :

```{r}
library(nycflights13)
library(tidyverse)
```

Why is it important to do this? When you are creating code, explicitly turning on packages that are required is considered good practice. This goes along with the importance of being intentional and making your code reproducible by anyone, anywhere. Tell the computer what to do...explicitly! Tell everyone explicitly when you have done to get to your results.

This also keeps your R sessions memory low and prevents duplicate functions from being loaded from different packages. Notice above when we load tidyverse we get the message that `✖ dplyr::filter() masks stats::filter()` and `✖ dplyr::lag()    masks stats::lag()`, that is because the stats package also has filter and lag functions as well as the dplyr package which is part of the tidyverse package. The tidyverse is actually a package of packages including ggplot2, purrr, tibble, dplyr, tidyr, stringr, readr, and forcats. We will learn more about all of these in coming weeks. In our case, because we more recently loaded tidyverse if we call `filter(some_argument...)` this will run the tidyverse/dplyr version of the function. As it says in [the reading](https://r4ds.had.co.nz/transform.html#prerequisites-2), if you want to use the base, or stats, version of these functions after loading dplyr, you'll need to specify the package that the function comes from using two colons `::` as in `stats::filter()` and `stats::lag().`

## 5.1.2

Run `flights` in the code chunk below. The output should match the reading. Note that you can find a nice README/data dictionary/documentation of this dataset by viewing its help documentation `?flights`.

```{r }

```

As described, `flights` is a data frame called a tibble. What does `int` mean on the third line of the table? Or `dbl`? 

These are types of variables. Be sure to familiarize yourself with the various types as you move forward, so focus on this section in [the reading](https://r4ds.had.co.nz/transform.html#prerequisites-2). You can also check out [Vectors and data types in Data Carpentry](https://datacarpentry.org/R-ecology-lesson/01-intro-to-r.html#Vectors_and_data_types).

## dplyr basics

# 5.2 filter()

The example filters the data based on month and day. `jan1 <- filter(flights, month == 1, day == 1)`

The double-equals sign implies "is equal to"; in the filter function above, all flights on the first day of January are saved as a new variable `jan1`.

What is happening in the command below?

```{r }
filter(flights, month == 1)
```

The reading also points out the use of the near function. Why is this important? Illustrate the example below in the code chunk below to reinforce the concept.

Paste `sqrt(1.9999999999999999999999)^2` in the code chunk and run it. If you keep removing the trailing 9s, when does the result not equal 2? What happens when you run `sqrt(2)^2==2`? Show me that you can have the computer make these equivalent using `near()`, and explain in one word---yes one word---the result of `sqrt(2)^2==2` versus using the near function. (Hint: the word starts with P).

```{r }

```

# 5.2.2 Logical Operators

We learned about `==`, "is equal to," above. Other logical or Boolean operators that can be used as filters are `>, =, <, <=, !=` (not equal). You can also combine these with other Logical or Boolean operators: `&` (and), `|` (or), and `!` (not).

![Complete set of boolean operations. x is the left-hand circle, y is the right-hand circle, and the shaded region show which parts each operator selects.](transform-logical.png)

How would you select all flights in May and June?

```{r }

```

## 5.2.3 Missing values

We covered `NA`s in some of our exercises last week. Hopefully reading through this section helped reinforce in your mind how `NA`s are handled in R and in the `dplyr::filter` function.

## 5.2.4 Exercises

These are additional practice to those in the book to reinforce the reading and try by doing. Solutions for each are given below. Our suggestion is to try first and test your skill.

1.  Find all flights that:

1.1 Had an arrival delay of two or more hours (10,034 flights)

1.2 Flew to Houston (IAH or HOU) (9,313 flights)

1.3 Were operated by United, American, or Delta (139,504 flights)

1.4 Departed in summer (July, August, and September) (86,326 flights)

1.5 Arrived more than two hours late, but didn't leave late (3 flights)

1.6 Were delayed by at least an hour, but made up over 30 minutes in flight (1,819 flights)

1.7 Departed between midnight and 6am (inclusive) (9,373 flights)

```{r }

```

2.  Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the 1.7? (hint: look up bwetween in the help menu. You'll see the required syntax, where x = vector, and left and right at the boundary values. You will also need to add an OR statement to include departure times at exactly 2400 since the dataframe has departures at both 0 and 2400)

```{r }

```

3.  How many flights have a missing dep_time? What other variables are missing? What might these rows represent?

```{r }

```

#solutions: 1.1 k \<- filter(flights,(arr_delay \> 120)) 1.2 k \<- filter(flights,dest == "IAH"\|dest=="HOU") 1.3 k \<- filter(flights,carrier=="DL"\|carrier=="UA"\|carrier=="AA") 1.4 k \<- filter(flights,month==7 \| month==8 \| month==9) 1.5 k \<- filter(flights,arr_delay \>120 & dep_delay == 0) 1.6 filter(flights,dep_delay \>60 & arr_delay \<(dep_delay-30))) 1.7 k \<- filter(flights,dep_time==2400 \| (dep_time\<0601)) 2. m \<- filter(flights,between(dep_time,0,0600)\|dep_time==2400) 3. y \<- filter(flights, is.na(dep_time))

## 5.3 Arrange

1. Use desc() to re-order by a column in descending order:

```{r }

```

2.  Sort flights to find the most delayed flights. Find the flights that left earliest.

```{r }

```

3.  Sort flights to find the fastest (highest speed) flights. Here you are creating a metric by using the existing data in the dataframe to calculate speed.

```{r }

```

4.  Which flights traveled the farthest? Which traveled the shortest?

(flights 1632 and 51)

```{r }
b <- arrange(flights, distance)
```

## 5.4 Select Columns

It's not uncommon to get datasets with hundreds or even thousands of variables. In this case, the first challenge is often narrowing in on the variables you're actually interested in. `select()` allows you to rapidly zoom in on a useful subset using operations based on the names of the variables.

`select()` is not terribly useful with the flights data because we only have 19 variables, but you can still get the general idea:

```{r}
select(flights, year, month, day)
```

\*\* Don't worry about 5.4.1 exercises

## 5.5 Add new variables

The functions `mutate` and `transmute` are used to add new variables/columns to a data frame.

Following [the example at the beginning of section 5.5 in the book](https://r4ds.had.co.nz/transform.html#add-new-variables-with-mutate), add a new speed variable using mutate to your data frame.

```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)

#add a speed variable


```

Now, create a new vector with just the speed vector using transmute. This allows you to create a new data frame and keep just the new variables that are calculated.

```{r}

```

Next, pay attention to the [Useful creation functions](https://r4ds.had.co.nz/transform.html#mutate-funs) modular arithmetic section to obtain hour and minutes from the departure data. Try for yourself below. This is pretty cool and can be useful.

```{r}

```

## 5.6 Grouped summaries

Grouped summaries are essentially what pivot tables are in Excel, if you have ever heard of those. By using the `summarise()` function with the `group_by` function we can, for example find the average flight delay by month. This becomes really awesome! This example starts with using `group_by` to group the data, then applies `summarise`.

```{r}
by_month <- group_by(flights, month)
f <- summarise(by_month, delay = mean(dep_delay, na.rm = TRUE))
```

## 5.6.1 Last concept:: Piping

In the example above, we ended up with 2 lines of code and created an intermediate dataframe called by_month. The second line of code then used this in the summarise function.

The idea of piping is that it can make it easier to write, follow, and understand what the commands are doing. Think of each pipe command as "then". The pipe command uses the following syntax : `%>%`. What it essentially does is take the result of the code on the left-hand side or previous line(s) and pass it as the first argument to the function on the right-hand side. 

We can recreate the example above with pipes. Written in words the code chunk below would be: ASSIGN a new object name,  
CHOOSE the dataset to operate on, THEN 
GROUP the dataset flights by month, THEN 
SUMMARIZE the mean of the departure delay.

```{r}
summary_FlightDelay <- # I like to use a new line here so that I can easily comment out the assignment while building my pipe
  flights %>%
  group_by(month) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE))
```

We'll get to making those sweet, sweet plots soon.


